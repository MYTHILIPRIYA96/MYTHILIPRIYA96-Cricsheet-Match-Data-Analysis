{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (9.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install mysql-connector-python\n",
    "! pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class CricketMatchParser:\n",
    "    def __init__(self, match_type, folder_path):\n",
    "        self.match_type = match_type\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    def parse_match(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            match_data = json.load(f)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        match_id = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # Extract basic metadata\n",
    "        info = match_data.get('info', {})\n",
    "        match_metadata = {\n",
    "            'match_id': match_id,\n",
    "            'match_type': info.get('match_type', self.match_type),\n",
    "            'venue': info.get('venue', ''),\n",
    "            'city': info.get('city', ''),\n",
    "            'date': info.get('dates', [''])[0],\n",
    "            'team1': info.get('teams', ['',''])[0],\n",
    "            'team2': info.get('teams', ['',''])[1],\n",
    "            'toss_winner': info.get('toss', {}).get('winner', ''),\n",
    "            'toss_decision': info.get('toss', {}).get('decision', ''),\n",
    "            'winner': info.get('outcome', {}).get('winner', ''),\n",
    "            'overs': info.get('overs', ''),\n",
    "            'season': info.get('season', '')\n",
    "        }\n",
    "\n",
    "        # Extract delivery-level data\n",
    "        delivery_data = []\n",
    "        innings = match_data.get('innings', [])\n",
    "        for inning in innings:\n",
    "            batting_team = inning.get('team', '')\n",
    "            overs = inning.get('overs', [])\n",
    "            for over_data in overs:\n",
    "                over_number = over_data.get('over')\n",
    "                deliveries = over_data.get('deliveries', [])\n",
    "                for ball_number, delivery in enumerate(deliveries, start=1):\n",
    "                    delivery_entry = {\n",
    "                        **match_metadata,# include all metadata in each row\n",
    "                        'batting_team': batting_team,\n",
    "                        'over': over_number,\n",
    "                        'ball': ball_number,\n",
    "                        'batter': delivery.get('batter', ''),\n",
    "                        'bowler': delivery.get('bowler', ''),\n",
    "                        'non_striker': delivery.get('non_striker', ''),\n",
    "                        'runs_batter': delivery.get('runs', {}).get('batter', 0),\n",
    "                        'runs_extras': delivery.get('runs', {}).get('extras', 0),\n",
    "                        'runs_total': delivery.get('runs', {}).get('total', 0),\n",
    "                        'extras_type': ','.join(delivery.get('extras', {}).keys()) if 'extras' in delivery else '',\n",
    "                        'wicket_type': '',\n",
    "                        'player_out': ''\n",
    "                    }\n",
    "\n",
    "                    # Handle wicket info\n",
    "                    if 'wickets' in delivery:\n",
    "                        for wicket in delivery['wickets']:\n",
    "                            delivery_entry['wicket_type'] = wicket.get('kind', '')\n",
    "                            delivery_entry['player_out'] = wicket.get('player_out', '')\n",
    "                    \n",
    "                    delivery_data.append(delivery_entry)\n",
    "\n",
    "        df = pd.DataFrame(delivery_data)\n",
    "        return df,match_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CricketDataTransformer:\n",
    "    def __init__(self, match_type, folder_path):\n",
    "        self.match_type = match_type\n",
    "        self.folder_path = folder_path\n",
    "        self.all_deliveries = []\n",
    "\n",
    "    def load_all_json_files(self):\n",
    "        parser = CricketMatchParser(self.match_type, self.folder_path)\n",
    "        for file in os.listdir(self.folder_path):\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(self.folder_path, file)\n",
    "                try:\n",
    "                    deliveries_df, match_id = parser.parse_match(file_path)\n",
    "                    if not deliveries_df.empty:\n",
    "                        self.all_deliveries.append(deliveries_df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to parse {file}: {e}\")\n",
    "\n",
    "    def get_combined_dataframe(self):\n",
    "        if self.all_deliveries:\n",
    "            return pd.concat(self.all_deliveries, ignore_index=True)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def save_to_csv(self, output_file):\n",
    "        df = self.get_combined_dataframe()\n",
    "        if not df.empty:\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved CSV: {output_file}\")\n",
    "        else:\n",
    "            print(f\"No data to save for {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test folder already exists, skipping extraction.\n",
      "Saved CSV: Test.csv\n",
      "ODI folder already exists, skipping extraction.\n",
      "Saved CSV: ODI.csv\n",
      "T20 folder already exists, skipping extraction.\n",
      "Saved CSV: T20.csv\n",
      "IPL folder already exists, skipping extraction.\n",
      "Saved CSV: IPL.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "# Match types and corresponding zip paths\n",
    "match_types = ['Test', 'ODI', 'T20', 'IPL']\n",
    "zip_paths = [\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\tests_json.zip',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\odis_json.zip',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\t20s_json.zip',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\ipl_json.zip'\n",
    "]\n",
    "extract_folders = [\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\tests_json',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\odis_json',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\t20s_json',\n",
    "    r'C:\\Users\\mythi\\Downloads\\JSON\\ipl_json'\n",
    "]\n",
    "\n",
    "# Loop through each match type\n",
    "for match_type, zip_path, extract_to in zip(match_types, zip_paths, extract_folders):\n",
    "    # Extract ZIP if folder doesn't exist\n",
    "    if not os.path.exists(extract_to):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted {match_type} JSON files to: {extract_to}\")\n",
    "    else:\n",
    "        print(f\"{match_type} folder already exists, skipping extraction.\")\n",
    "\n",
    "    # Load JSON files using your CricketDataTransformer class\n",
    "    transformer = CricketDataTransformer(match_type,extract_to)\n",
    "    transformer.load_all_json_files()\n",
    "    transformer.save_to_csv(f'{match_type}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.38)\n",
      "Requirement already satisfied: pandas in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install mysql-connector-python sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mythi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mythi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n",
      "Table created or already exists.\n",
      "Table created or already exists.\n",
      "Table created or already exists.\n",
      "Table created or already exists.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "#  Database Class \n",
    "class Database:\n",
    "    def __init__(self, host, user, password, port, database):\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.port = port\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        self.connection = mysql.connector.connect(\n",
    "            host=self.host,\n",
    "            user=self.user,\n",
    "            password=self.password,\n",
    "            port=self.port,\n",
    "            connection_timeout=300,\n",
    "            read_timeout=300,\n",
    "            write_timeout=300,\n",
    "            autocommit=True\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "        print(\"Connection established.\")\n",
    "        self.cursor.execute(\"SET GLOBAL max_allowed_packet=536870912\")  # 512MB\n",
    "        self.cursor.execute(\"SET SESSION wait_timeout=28800\")\n",
    "        self.create_database()\n",
    "        self.cursor.execute(f\"USE {self.database}\")\n",
    "        self.connection.commit()\n",
    "\n",
    "    def create_database(self):\n",
    "        sql = f\"CREATE DATABASE IF NOT EXISTS {self.database}\"\n",
    "        self.cursor.execute(sql)\n",
    "        self.connection.commit()\n",
    "\n",
    "    def create_tables(self):\n",
    "        create_table_queries = [\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS test_matches (\n",
    "                match_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                match_type VARCHAR(20),\n",
    "                venue VARCHAR(255),\n",
    "                city VARCHAR(100),\n",
    "                date DATE,\n",
    "                team1 VARCHAR(100),\n",
    "                team2 VARCHAR(100),\n",
    "                toss_winner VARCHAR(100),\n",
    "                toss_decision VARCHAR(10),\n",
    "                winner VARCHAR(100),\n",
    "                overs INT,\n",
    "                season VARCHAR(20),\n",
    "                batting_team VARCHAR(100),\n",
    "                `over` INT,\n",
    "                ball INT,\n",
    "                batter VARCHAR(100),\n",
    "                bowler VARCHAR(100),\n",
    "                non_striker VARCHAR(100),\n",
    "                runs_batter INT,\n",
    "                runs_extras INT,\n",
    "                runs_total INT,\n",
    "                extras_type VARCHAR(100),\n",
    "                wicket_type VARCHAR(100),\n",
    "                player_out VARCHAR(100)\n",
    "            );\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS odi_matches (\n",
    "                delivery_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                match_id VARCHAR(100),\n",
    "                match_type VARCHAR(20),\n",
    "                venue VARCHAR(255),\n",
    "                city VARCHAR(100),\n",
    "                date DATE,\n",
    "                team1 VARCHAR(100),\n",
    "                team2 VARCHAR(100),\n",
    "                toss_winner VARCHAR(100),\n",
    "                toss_decision VARCHAR(10),\n",
    "                winner VARCHAR(100),\n",
    "                overs INT,\n",
    "                season VARCHAR(20),\n",
    "                batting_team VARCHAR(100),\n",
    "                `over` INT,\n",
    "                ball INT,\n",
    "                batter VARCHAR(100),\n",
    "                bowler VARCHAR(100),\n",
    "                non_striker VARCHAR(100),\n",
    "                runs_batter INT,\n",
    "                runs_extras INT,\n",
    "                runs_total INT,\n",
    "                extras_type VARCHAR(100),\n",
    "                wicket_type VARCHAR(100),\n",
    "                player_out VARCHAR(100)\n",
    "            );\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS t20_matches (\n",
    "                delivery_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                match_id VARCHAR(100),\n",
    "                match_type VARCHAR(20),\n",
    "                venue VARCHAR(255),\n",
    "                city VARCHAR(100),\n",
    "                date DATE,\n",
    "                team1 VARCHAR(100),\n",
    "                team2 VARCHAR(100),\n",
    "                toss_winner VARCHAR(100),\n",
    "                toss_decision VARCHAR(10),\n",
    "                winner VARCHAR(100),\n",
    "                overs INT,\n",
    "                season VARCHAR(20),\n",
    "                batting_team VARCHAR(100),\n",
    "                `over` INT,\n",
    "                ball INT,\n",
    "                batter VARCHAR(100),\n",
    "                bowler VARCHAR(100),\n",
    "                non_striker VARCHAR(100),\n",
    "                runs_batter INT,\n",
    "                runs_extras INT,\n",
    "                runs_total INT,\n",
    "                extras_type VARCHAR(100),\n",
    "                wicket_type VARCHAR(100),\n",
    "                player_out VARCHAR(100)\n",
    "            );\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS ipl_matches (\n",
    "                delivery_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                match_id VARCHAR(100),\n",
    "                match_type VARCHAR(20),\n",
    "                venue VARCHAR(255),\n",
    "                city VARCHAR(100),\n",
    "                date DATE,\n",
    "                team1 VARCHAR(100),\n",
    "                team2 VARCHAR(100),\n",
    "                toss_winner VARCHAR(100),\n",
    "                toss_decision VARCHAR(10),\n",
    "                winner VARCHAR(100),\n",
    "                overs INT,\n",
    "                season VARCHAR(20),\n",
    "                batting_team VARCHAR(100),\n",
    "                `over` INT,\n",
    "                ball INT,\n",
    "                batter VARCHAR(100),\n",
    "                bowler VARCHAR(100),\n",
    "                non_striker VARCHAR(100),\n",
    "                runs_batter INT,\n",
    "                runs_extras INT,\n",
    "                runs_total INT,\n",
    "                extras_type VARCHAR(100),\n",
    "                wicket_type VARCHAR(50),\n",
    "                player_out VARCHAR(100)\n",
    "            );\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        for ddl in create_table_queries:\n",
    "            try:\n",
    "                self.cursor.execute(ddl)\n",
    "                print(\"Table created or already exists.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating table: {e}\")\n",
    "        self.connection.commit()\n",
    "\n",
    "# Instantiate and use the class\n",
    "db = Database(host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",user=\"34g2VqGrtKaDYbo.root\", password=\"hbsne8KH4QKKfIT3\", port=4000, database=\"cricsheet_analysis\")\n",
    "db.connect()\n",
    "db.create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "def insert_match_data(cursor, connection, df, table_name, batch_size=100):\n",
    "    expected_columns = [\n",
    "        'match_id', 'match_type', 'venue', 'city', 'date', 'team1', 'team2',\n",
    "        'toss_winner', 'toss_decision', 'winner', 'overs', 'season',\n",
    "        'batting_team', 'over', 'ball', 'batter', 'bowler', 'non_striker',\n",
    "        'runs_batter', 'runs_extras', 'runs_total', 'extras_type', 'wicket_type', 'player_out'\n",
    "    ]\n",
    "    \n",
    "    missing = [col for col in expected_columns if col not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"Missing columns in `{table_name}` DataFrame: {missing}\")\n",
    "        return\n",
    "\n",
    "    # Clean and prepare data\n",
    "    df = df.replace({np.nan: None, 'nan': None})\n",
    "    df = df.dropna(subset=['match_id']) \n",
    "    df = df.drop_duplicates(subset=['match_id']) \n",
    "    fill_values = {\n",
    "        'match_type': 'unknown',\n",
    "        'venue': 'unknown',\n",
    "        'city': 'unknown',\n",
    "        'team1': 'unknown',\n",
    "        'team2': 'unknown',\n",
    "        'toss_winner': 'unknown',\n",
    "        'toss_decision': 'unknown',\n",
    "        'winner': 'unknown',\n",
    "        'season': 'unknown',\n",
    "        'batting_team': 'unknown',\n",
    "        'batter': 'unknown',\n",
    "        'bowler': 'unknown',\n",
    "        'non_striker': 'unknown',\n",
    "        'extras_type': 'none',\n",
    "        'wicket_type': 'none',\n",
    "        'player_out': 'none',\n",
    "        'runs_batter': 0,\n",
    "        'runs_extras': 0,\n",
    "        'runs_total': 0,\n",
    "        'overs': 0,\n",
    "        'over': 0,\n",
    "        'ball': 0\n",
    "    }\n",
    "\n",
    "    df.fillna(value=fill_values, inplace=True)\n",
    "    \n",
    "    insert_query = f\"\"\"\n",
    "        INSERT IGNORE INTO {table_name} (\n",
    "            match_id, match_type, venue, city, date, team1, team2,\n",
    "            toss_winner, toss_decision, winner, overs, season,\n",
    "            batting_team, `over`, ball, batter, bowler, non_striker,\n",
    "            runs_batter, runs_extras, runs_total, extras_type, wicket_type, player_out\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Starting data insertion into table `{table_name}`...\")\n",
    "\n",
    "    try:\n",
    "        all_data = [\n",
    "            (\n",
    "                row.get('match_id'), row.get('match_type'), row.get('venue'), row.get('city'), row.get('date'),\n",
    "                row.get('team1'), row.get('team2'), row.get('toss_winner'), row.get('toss_decision'), row.get('winner'),\n",
    "                row.get('overs'), row.get('season'), row.get('batting_team'), row.get('over'), row.get('ball'),\n",
    "                row.get('batter'), row.get('bowler'), row.get('non_striker'), row.get('runs_batter'), row.get('runs_extras'),\n",
    "                row.get('runs_total'), row.get('extras_type'), row.get('wicket_type'), row.get('player_out')\n",
    "            ) for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        total_rows = len(all_data)\n",
    "        for start in range(0, total_rows, batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = all_data[start:end]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "            connection.commit()\n",
    "            print(f\"Inserted rows {start+1} to {min(end, total_rows)}\")\n",
    "\n",
    "        print(f\"Data insertion complete for table `{table_name}`\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into `{table_name}`: {e}\")\n",
    "        connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data insertion into table `ipl_matches`...\n",
      "Inserted rows 1 to 100\n",
      "Inserted rows 101 to 200\n",
      "Inserted rows 201 to 300\n",
      "Inserted rows 301 to 400\n",
      "Inserted rows 401 to 500\n",
      "Inserted rows 501 to 600\n",
      "Inserted rows 601 to 700\n",
      "Inserted rows 701 to 800\n",
      "Inserted rows 801 to 900\n",
      "Inserted rows 901 to 1000\n",
      "Inserted rows 1001 to 1095\n",
      "Data insertion complete for table `ipl_matches`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mythi\\AppData\\Local\\Temp\\ipykernel_17528\\2938297941.py:47: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.fillna(value=fill_values, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data insertion into table `test_matches`...\n",
      "Inserted rows 1 to 100\n",
      "Inserted rows 101 to 200\n",
      "Inserted rows 201 to 300\n",
      "Inserted rows 301 to 400\n",
      "Inserted rows 401 to 500\n",
      "Inserted rows 501 to 600\n",
      "Inserted rows 601 to 700\n",
      "Inserted rows 701 to 800\n",
      "Inserted rows 801 to 861\n",
      "Data insertion complete for table `test_matches`\n",
      "Starting data insertion into table `odi_matches`...\n",
      "Inserted rows 1 to 100\n",
      "Inserted rows 101 to 200\n",
      "Inserted rows 201 to 300\n",
      "Inserted rows 301 to 400\n",
      "Inserted rows 401 to 500\n",
      "Inserted rows 501 to 600\n",
      "Inserted rows 601 to 700\n",
      "Inserted rows 701 to 800\n",
      "Inserted rows 801 to 900\n",
      "Inserted rows 901 to 1000\n",
      "Inserted rows 1001 to 1100\n",
      "Inserted rows 1101 to 1200\n",
      "Inserted rows 1201 to 1300\n",
      "Inserted rows 1301 to 1400\n",
      "Inserted rows 1401 to 1500\n",
      "Inserted rows 1501 to 1600\n",
      "Inserted rows 1601 to 1700\n",
      "Inserted rows 1701 to 1800\n",
      "Inserted rows 1801 to 1900\n",
      "Inserted rows 1901 to 2000\n",
      "Inserted rows 2001 to 2100\n",
      "Inserted rows 2101 to 2200\n",
      "Inserted rows 2201 to 2300\n",
      "Inserted rows 2301 to 2400\n",
      "Inserted rows 2401 to 2500\n",
      "Inserted rows 2501 to 2600\n",
      "Inserted rows 2601 to 2700\n",
      "Inserted rows 2701 to 2800\n",
      "Inserted rows 2801 to 2900\n",
      "Inserted rows 2901 to 2915\n",
      "Data insertion complete for table `odi_matches`\n",
      "Starting data insertion into table `t20_matches`...\n",
      "Inserted rows 1 to 100\n",
      "Inserted rows 101 to 200\n",
      "Inserted rows 201 to 300\n",
      "Inserted rows 301 to 400\n",
      "Inserted rows 401 to 500\n",
      "Inserted rows 501 to 600\n",
      "Inserted rows 601 to 700\n",
      "Inserted rows 701 to 800\n",
      "Inserted rows 801 to 900\n",
      "Inserted rows 901 to 1000\n",
      "Inserted rows 1001 to 1100\n",
      "Inserted rows 1101 to 1200\n",
      "Inserted rows 1201 to 1300\n",
      "Inserted rows 1301 to 1400\n",
      "Inserted rows 1401 to 1500\n",
      "Inserted rows 1501 to 1600\n",
      "Inserted rows 1601 to 1700\n",
      "Inserted rows 1701 to 1800\n",
      "Inserted rows 1801 to 1900\n",
      "Inserted rows 1901 to 2000\n",
      "Inserted rows 2001 to 2100\n",
      "Inserted rows 2101 to 2200\n",
      "Inserted rows 2201 to 2300\n",
      "Inserted rows 2301 to 2400\n",
      "Inserted rows 2401 to 2500\n",
      "Inserted rows 2501 to 2600\n",
      "Inserted rows 2601 to 2700\n",
      "Inserted rows 2701 to 2800\n",
      "Inserted rows 2801 to 2900\n",
      "Inserted rows 2901 to 3000\n",
      "Inserted rows 3001 to 3100\n",
      "Inserted rows 3101 to 3200\n",
      "Inserted rows 3201 to 3300\n",
      "Inserted rows 3301 to 3400\n",
      "Inserted rows 3401 to 3500\n",
      "Inserted rows 3501 to 3600\n",
      "Inserted rows 3601 to 3700\n",
      "Inserted rows 3701 to 3800\n",
      "Inserted rows 3801 to 3900\n",
      "Inserted rows 3901 to 4000\n",
      "Inserted rows 4001 to 4008\n",
      "Data insertion complete for table `t20_matches`\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Read each file into a separate DataFrame\n",
    "        df_ipl = pd.read_csv(\"IPL.csv\", low_memory=False)\n",
    "        df_test = pd.read_csv(\"Test.csv\", low_memory=False)\n",
    "        df_odi = pd.read_csv(\"ODI.csv\", low_memory=False)\n",
    "        df_t20 = pd.read_csv(\"T20.csv\", low_memory=False)\n",
    "\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "            user=\"34g2VqGrtKaDYbo.root\",\n",
    "            password=\"hbsne8KH4QKKfIT3\",\n",
    "            port=\"4000\",\n",
    "            database=\"cricsheet_analysis\"\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Insert into each table using its respective DataFrame\n",
    "        insert_match_data(cursor, connection, df_ipl, table_name=\"ipl_matches\", batch_size=100)\n",
    "        insert_match_data(cursor, connection, df_test, table_name=\"test_matches\", batch_size=100)\n",
    "        insert_match_data(cursor, connection, df_odi, table_name=\"odi_matches\", batch_size=100)\n",
    "        insert_match_data(cursor, connection, df_t20, table_name=\"t20_matches\", batch_size=100)\n",
    "\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPL: 260920\n",
      "TEST: 1669269\n",
      "ODI: 1542876\n",
      "T20: 906734\n"
     ]
    }
   ],
   "source": [
    "print(\"IPL:\", len(df_ipl))\n",
    "print(\"TEST:\", len(df_test))\n",
    "print(\"ODI:\", len(df_odi))\n",
    "print(\"T20:\", len(df_t20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
